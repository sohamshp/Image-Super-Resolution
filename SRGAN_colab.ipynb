{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hS_-axBwMHW6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorlayer easydict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rPqkAwx1Ra3i",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install megatools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CvdoNNbWgxem",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y8DZVI8XRdl2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!megadl \"https://mega.nz/#!xZ8glS6J!MAnE91ND_WyfZ_8mvkuSa2YcA7q-1ehfSm-Q1fxOvvs\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "No6gbrW3o4lv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eVzeSKjzo4aP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UFsDgPGctTHK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8eK32np6twO_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSDMO_-TeVcV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qrfopjJ0fEXg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y software-properties-common python-software-properties module-init-tools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2H0GanTCfJJU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!add-apt-repository -y ppa:alessandro-strada/ppa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zEizUcX2fM6L",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3JqtIsIZfQXl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get -y install google-drive-ocamlfuse fuse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q0u3VR-gmbF4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get update -qq #2>&1 > /dev/null\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa #2>&1 > /dev/null\n",
        "!apt-get update -qq #2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XoDG4oKpoeyS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e1aYVoLod-YD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!google-drive-ocamlfuse -verbose -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y8qi-uTafqCj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qWfqfQrCfih-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "creds.client_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4r-lVzSgeQfi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "creds.client_secret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Jk9jZm8mhFX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "# Work around misordering of STREAM and STDIN in Jupyter.\n",
        "# https://github.com/jupyter/notebook/issues/3159\n",
        "prompt = !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass(prompt[0] + '\\n\\nEnter verification code: ')\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c99EvWo1s9-x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "print('Files in Drive:')\n",
        "!ls drive/\n",
        "\n",
        "# Create a file in Drive.\n",
        "!echo \"This newly created file will appear in your Drive file list.\" > drive/created.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A0MvudfjtthG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#### dataset.zip File ID: 1IstPsPA0mFfgdOMn6XLAMKy0unZFpOFT\n",
        "\n",
        "file_id = '1IstPsPA0mFfgdOMn6XLAMKy0unZFpOFT'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2YaFdmgHMra7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## Downloading DIV2K dataset for 4X downscaling.\n",
        "\n",
        "# training LR images\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip\n",
        "# validation LR images\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_LR_bicubic_X4.zip\n",
        "# training HR images\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "# validation HR images\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xv-12Sp0Mx9-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir data2017"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xdgXFytHuxwB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip -d ./ drive/dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4FgoatAbvmFY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QqoN9Op0MzCr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip -d data2017 DIV2K_train_LR_bicubic_X4.zip\n",
        "!unzip -d data2017 DIV2K_valid_LR_bicubic_X4.zip\n",
        "!unzip -d data2017 DIV2K_train_HR.zip\n",
        "!unzip -d data2017 DIV2K_valid_HR.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LS83aUs9M4E0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls data2017"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i-vnfe_pLvE1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorlayer as tl\n",
        "import numpy as np\n",
        "import logging\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "import scipy\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "\n",
        "from easydict import EasyDict as edict\n",
        "#from config import config, log_config\n",
        "from time import localtime, strftime\n",
        "from tensorlayer.layers import *\n",
        "from tensorlayer.prepro import *\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HLWVwTt-LvE7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_imgs_fn(file_name, path):\n",
        "    return scipy.misc.imread(os.path.join(path, file_name), mode='RGB')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zzGQncA5LvE-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def crop_sub_img_fn(x, is_random=True):\n",
        "    x = crop(x, wrg=384, hrg=384, is_random=is_random)\n",
        "    x = x / (255. / 2.)\n",
        "    x = x - 1.\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aZ5oeIxKLvFB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def downsample_fn(x):\n",
        "    x = scipy.misc.imresize(x, size=[96,96], interp='bicubic', mode=None)\n",
        "    x = x / (255. / 2.)\n",
        "    x = x - 1.\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gWlLy9RbLvFF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def log_config(filename, cfg):\n",
        "    with open(filename, 'w') as f:\n",
        "        f.wrtie('----------------------------------\\n')\n",
        "        f.write(json.dumps(cfg, indent=4))\n",
        "        f.wrtie('----------------------------------\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fP6NyXRdLvFJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model functions"
      ]
    },
    {
      "metadata": {
        "id": "c3fapMgKLvFL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def SRGAN_g(t_image, is_train=False, reuse=False):\n",
        "    \"\"\" Generator in Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\n",
        "    feature maps (n) and stride (s) feature maps (n) and stride (s)\n",
        "    \"\"\"\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
        "    b_init = None  # tf.constant_initializer(value=0.0)\n",
        "    g_init = tf.random_normal_initializer(1., 0.02)\n",
        "    with tf.variable_scope(\"SRGAN_g\", reuse=reuse) as vs:\n",
        "        tl.layers.set_name_reuse(reuse)\n",
        "        n = InputLayer(t_image, name='in')\n",
        "        n = Conv2d(n, 64, (3, 3), (1, 1), act=tf.nn.relu, padding='SAME', W_init=w_init, name='n64s1/c')\n",
        "        temp = n\n",
        "\n",
        "        # B residual blocks\n",
        "        for i in range(16):\n",
        "            nn = Conv2d(n, 64, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='n64s1/c1/%s' % i)\n",
        "            nn = BatchNormLayer(nn, act=tf.nn.relu, is_train=is_train, gamma_init=g_init, name='n64s1/b1/%s' % i)\n",
        "            nn = Conv2d(nn, 64, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='n64s1/c2/%s' % i)\n",
        "            nn = BatchNormLayer(nn, is_train=is_train, gamma_init=g_init, name='n64s1/b2/%s' % i)\n",
        "            nn = ElementwiseLayer([n, nn], tf.add, name='b_residual_add/%s' % i)\n",
        "            n = nn\n",
        "\n",
        "        n = Conv2d(n, 64, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='n64s1/c/m')\n",
        "        n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name='n64s1/b/m')\n",
        "        n = ElementwiseLayer([n, temp], tf.add, name='add3')\n",
        "        # B residual blacks end\n",
        "\n",
        "        n = Conv2d(n, 256, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, name='n256s1/1')\n",
        "        n = SubpixelConv2d(n, scale=2, n_out_channel=None, act=tf.nn.relu, name='pixelshufflerx2/1')\n",
        "\n",
        "        n = Conv2d(n, 256, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, name='n256s1/2')\n",
        "        n = SubpixelConv2d(n, scale=2, n_out_channel=None, act=tf.nn.relu, name='pixelshufflerx2/2')\n",
        "\n",
        "        n = Conv2d(n, 3, (1, 1), (1, 1), act=tf.nn.tanh, padding='SAME', W_init=w_init, name='out')\n",
        "        return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "StONnQCxLvFO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def SRGAN_g2(t_image, is_train=False, reuse=False):\n",
        "    \"\"\" Generator in Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\n",
        "    feature maps (n) and stride (s) feature maps (n) and stride (s)\n",
        "\n",
        "    96x96 --> 384x384\n",
        "\n",
        "    Use Resize Conv\n",
        "    \"\"\"\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
        "    b_init = None  # tf.constant_initializer(value=0.0)\n",
        "    g_init = tf.random_normal_initializer(1., 0.02)\n",
        "    size = t_image.get_shape().as_list()\n",
        "    with tf.variable_scope(\"SRGAN_g\", reuse=reuse) as vs:\n",
        "        tl.layers.set_name_reuse(reuse)\n",
        "        n = InputLayer(t_image, name='in')\n",
        "        n = Conv2d(n, 64, (3, 3), (1, 1), act=tf.nn.relu, padding='SAME', W_init=w_init, name='n64s1/c')\n",
        "        temp = n\n",
        "\n",
        "        # B residual blocks\n",
        "        for i in range(16):\n",
        "            nn = Conv2d(n, 64, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='n64s1/c1/%s' % i)\n",
        "            nn = BatchNormLayer(nn, act=tf.nn.relu, is_train=is_train, gamma_init=g_init, name='n64s1/b1/%s' % i)\n",
        "            nn = Conv2d(nn, 64, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='n64s1/c2/%s' % i)\n",
        "            nn = BatchNormLayer(nn, is_train=is_train, gamma_init=g_init, name='n64s1/b2/%s' % i)\n",
        "            nn = ElementwiseLayer([n, nn], tf.add, 'b_residual_add/%s' % i)\n",
        "            n = nn\n",
        "\n",
        "        n = Conv2d(n, 64, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='n64s1/c/m')\n",
        "        n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name='n64s1/b/m')\n",
        "        n = ElementwiseLayer([n, temp], tf.add, 'add3')\n",
        "        # B residual blacks end\n",
        "\n",
        "        # n = Conv2d(n, 256, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, name='n256s1/1')\n",
        "        # n = SubpixelConv2d(n, scale=2, n_out_channel=None, act=tf.nn.relu, name='pixelshufflerx2/1')\n",
        "        #\n",
        "        # n = Conv2d(n, 256, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, name='n256s1/2')\n",
        "        # n = SubpixelConv2d(n, scale=2, n_out_channel=None, act=tf.nn.relu, name='pixelshufflerx2/2')\n",
        "\n",
        "        ## 0, 1, 2, 3 BILINEAR NEAREST BICUBIC AREA\n",
        "        n = UpSampling2dLayer(n, size=[size[1] * 2, size[2] * 2], is_scale=False, method=1, align_corners=False, name='up1/upsample2d')\n",
        "        n = Conv2d(n, 64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=b_init, name='up1/conv2d')  # <-- may need to increase n_filter\n",
        "        n = BatchNormLayer(n, act=tf.nn.relu, is_train=is_train, gamma_init=g_init, name='up1/batch_norm')\n",
        "\n",
        "        n = UpSampling2dLayer(n, size=[size[1] * 4, size[2] * 4], is_scale=False, method=1, align_corners=False, name='up2/upsample2d')\n",
        "        n = Conv2d(n, 32, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=b_init, name='up2/conv2d')  # <-- may need to increase n_filter\n",
        "        n = BatchNormLayer(n, act=tf.nn.relu, is_train=is_train, gamma_init=g_init, name='up2/batch_norm')\n",
        "\n",
        "        n = Conv2d(n, 3, (1, 1), (1, 1), act=tf.nn.tanh, padding='SAME', W_init=w_init, name='out')\n",
        "        return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Khv9YOZVLvFS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def SRGAN_d2(t_image, is_train=False, reuse=False):\n",
        "    \"\"\" Discriminator in Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\n",
        "    feature maps (n) and stride (s) feature maps (n) and stride (s)\n",
        "    \"\"\"\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
        "    b_init = None\n",
        "    g_init = tf.random_normal_initializer(1., 0.02)\n",
        "    lrelu = lambda x: tl.act.lrelu(x, 0.2)\n",
        "    with tf.variable_scope(\"SRGAN_d\", reuse=reuse) as vs:\n",
        "        tl.layers.set_name_reuse(reuse)\n",
        "        n = InputLayer(t_image, name='in')\n",
        "        n = Conv2d(n, 64, (3, 3), (1, 1), act=lrelu, padding='SAME', W_init=w_init, name='n64s1/c')\n",
        "\n",
        "        n = Conv2d(n, 64, (3, 3), (2, 2), act=lrelu, padding='SAME', W_init=w_init, b_init=b_init, name='n64s2/c')\n",
        "        n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name='n64s2/b')\n",
        "\n",
        "        n = Conv2d(n, 128, (3, 3), (1, 1), act=lrelu, padding='SAME', W_init=w_init, b_init=b_init, name='n128s1/c')\n",
        "        n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name='n128s1/b')\n",
        "\n",
        "        n = Conv2d(n, 128, (3, 3), (2, 2), act=lrelu, padding='SAME', W_init=w_init, b_init=b_init, name='n128s2/c')\n",
        "        n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name='n128s2/b')\n",
        "\n",
        "        n = Conv2d(n, 256, (3, 3), (1, 1), act=lrelu, padding='SAME', W_init=w_init, b_init=b_init, name='n256s1/c')\n",
        "        n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name='n256s1/b')\n",
        "\n",
        "        n = Conv2d(n, 256, (3, 3), (2, 2), act=lrelu, padding='SAME', W_init=w_init, b_init=b_init, name='n256s2/c')\n",
        "        n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name='n256s2/b')\n",
        "\n",
        "        n = Conv2d(n, 512, (3, 3), (1, 1), act=lrelu, padding='SAME', W_init=w_init, b_init=b_init, name='n512s1/c')\n",
        "        n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name='n512s1/b')\n",
        "\n",
        "        n = Conv2d(n, 512, (3, 3), (2, 2), act=lrelu, padding='SAME', W_init=w_init, b_init=b_init, name='n512s2/c')\n",
        "        n = BatchNormLayer(n, is_train=is_train, gamma_init=g_init, name='n512s2/b')\n",
        "\n",
        "        n = FlattenLayer(n, name='f')\n",
        "        n = DenseLayer(n, n_units=1024, act=lrelu, name='d1024')\n",
        "        n = DenseLayer(n, n_units=1, name='out')\n",
        "\n",
        "        logits = n.outputs\n",
        "        n.outputs = tf.nn.sigmoid(n.outputs)\n",
        "\n",
        "        return n, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPBRU87tLvFV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def SRGAN_d(input_images, is_train=True, reuse=False):\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
        "    b_init = None  # tf.constant_initializer(value=0.0)\n",
        "    gamma_init = tf.random_normal_initializer(1., 0.02)\n",
        "    df_dim = 64\n",
        "    lrelu = lambda x: tl.act.lrelu(x, 0.2)\n",
        "    with tf.variable_scope(\"SRGAN_d\", reuse=reuse):\n",
        "        tl.layers.set_name_reuse(reuse)\n",
        "        net_in = InputLayer(input_images, name='input/images')\n",
        "        net_h0 = Conv2d(net_in, df_dim, (4, 4), (2, 2), act=lrelu, padding='SAME', W_init=w_init, name='h0/c')\n",
        "\n",
        "        net_h1 = Conv2d(net_h0, df_dim * 2, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h1/c')\n",
        "        net_h1 = BatchNormLayer(net_h1, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='h1/bn')\n",
        "        net_h2 = Conv2d(net_h1, df_dim * 4, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h2/c')\n",
        "        net_h2 = BatchNormLayer(net_h2, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='h2/bn')\n",
        "        net_h3 = Conv2d(net_h2, df_dim * 8, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h3/c')\n",
        "        net_h3 = BatchNormLayer(net_h3, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='h3/bn')\n",
        "        net_h4 = Conv2d(net_h3, df_dim * 16, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h4/c')\n",
        "        net_h4 = BatchNormLayer(net_h4, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='h4/bn')\n",
        "        net_h5 = Conv2d(net_h4, df_dim * 32, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h5/c')\n",
        "        net_h5 = BatchNormLayer(net_h5, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='h5/bn')\n",
        "        net_h6 = Conv2d(net_h5, df_dim * 16, (1, 1), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h6/c')\n",
        "        net_h6 = BatchNormLayer(net_h6, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='h6/bn')\n",
        "        net_h7 = Conv2d(net_h6, df_dim * 8, (1, 1), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='h7/c')\n",
        "        net_h7 = BatchNormLayer(net_h7, is_train=is_train, gamma_init=gamma_init, name='h7/bn')\n",
        "\n",
        "        net = Conv2d(net_h7, df_dim * 2, (1, 1), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='res/c')\n",
        "        net = BatchNormLayer(net, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='res/bn')\n",
        "        net = Conv2d(net, df_dim * 2, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='res/c2')\n",
        "        net = BatchNormLayer(net, act=lrelu, is_train=is_train, gamma_init=gamma_init, name='res/bn2')\n",
        "        net = Conv2d(net, df_dim * 8, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init, b_init=b_init, name='res/c3')\n",
        "        net = BatchNormLayer(net, is_train=is_train, gamma_init=gamma_init, name='res/bn3')\n",
        "        net_h8 = ElementwiseLayer([net_h7, net], combine_fn=tf.add, name='res/add')\n",
        "        net_h8.outputs = tl.act.lrelu(net_h8.outputs, 0.2)\n",
        "\n",
        "        net_ho = FlattenLayer(net_h8, name='ho/flatten')\n",
        "        net_ho = DenseLayer(net_ho, n_units=1, act=tf.identity, W_init=w_init, name='ho/dense')\n",
        "        logits = net_ho.outputs\n",
        "        net_ho.outputs = tf.nn.sigmoid(net_ho.outputs)\n",
        "\n",
        "    return net_ho, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PM1SIoDXLvFe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def Vgg19_simple_api(rgb, reuse):\n",
        "    \"\"\"\n",
        "    Build the VGG 19 Model\n",
        "\n",
        "    Parameters\n",
        "    -----------\n",
        "    rgb : rgb image placeholder [batch, height, width, 3] values scaled [0, 1]\n",
        "    \"\"\"\n",
        "    VGG_MEAN = [103.939, 116.779, 123.68]\n",
        "    with tf.variable_scope(\"VGG19\", reuse=reuse) as vs:\n",
        "        start_time = time.time()\n",
        "        print(\"build model started\")\n",
        "        rgb_scaled = rgb * 255.0\n",
        "        # Convert RGB to BGR\n",
        "        if tf.__version__ <= '0.11':\n",
        "            red, green, blue = tf.split(3, 3, rgb_scaled)\n",
        "        else:  # TF 1.0\n",
        "            # print(rgb_scaled)\n",
        "            red, green, blue = tf.split(rgb_scaled, 3, 3)\n",
        "        assert red.get_shape().as_list()[1:] == [224, 224, 1]\n",
        "        assert green.get_shape().as_list()[1:] == [224, 224, 1]\n",
        "        assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n",
        "        if tf.__version__ <= '0.11':\n",
        "            bgr = tf.concat(3, [\n",
        "                blue - VGG_MEAN[0],\n",
        "                green - VGG_MEAN[1],\n",
        "                red - VGG_MEAN[2],\n",
        "            ])\n",
        "        else:\n",
        "            bgr = tf.concat(\n",
        "                [\n",
        "                    blue - VGG_MEAN[0],\n",
        "                    green - VGG_MEAN[1],\n",
        "                    red - VGG_MEAN[2],\n",
        "                ], axis=3)\n",
        "        assert bgr.get_shape().as_list()[1:] == [224, 224, 3]\n",
        "        \"\"\" input layer \"\"\"\n",
        "        net_in = InputLayer(bgr, name='input')\n",
        "        \"\"\" conv1 \"\"\"\n",
        "        network = Conv2d(net_in, n_filter=64, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv1_1')\n",
        "        network = Conv2d(network, n_filter=64, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv1_2')\n",
        "        network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding='SAME', name='pool1')\n",
        "        \"\"\" conv2 \"\"\"\n",
        "        network = Conv2d(network, n_filter=128, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv2_1')\n",
        "        network = Conv2d(network, n_filter=128, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv2_2')\n",
        "        network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding='SAME', name='pool2')\n",
        "        \"\"\" conv3 \"\"\"\n",
        "        network = Conv2d(network, n_filter=256, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv3_1')\n",
        "        network = Conv2d(network, n_filter=256, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv3_2')\n",
        "        network = Conv2d(network, n_filter=256, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv3_3')\n",
        "        network = Conv2d(network, n_filter=256, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv3_4')\n",
        "        network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding='SAME', name='pool3')\n",
        "        \"\"\" conv4 \"\"\"\n",
        "        network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv4_1')\n",
        "        network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv4_2')\n",
        "        network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv4_3')\n",
        "        network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv4_4')\n",
        "        network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding='SAME', name='pool4')  # (batch_size, 14, 14, 512)\n",
        "        conv = network\n",
        "        \"\"\" conv5 \"\"\"\n",
        "        network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv5_1')\n",
        "        network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv5_2')\n",
        "        network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv5_3')\n",
        "        network = Conv2d(network, n_filter=512, filter_size=(3, 3), strides=(1, 1), act=tf.nn.relu, padding='SAME', name='conv5_4')\n",
        "        network = MaxPool2d(network, filter_size=(2, 2), strides=(2, 2), padding='SAME', name='pool5')  # (batch_size, 7, 7, 512)\n",
        "        \"\"\" fc 6~8 \"\"\"\n",
        "        network = FlattenLayer(network, name='flatten')\n",
        "        network = DenseLayer(network, n_units=4096, act=tf.nn.relu, name='fc6')\n",
        "        network = DenseLayer(network, n_units=4096, act=tf.nn.relu, name='fc7')\n",
        "        network = DenseLayer(network, n_units=1000, act=tf.identity, name='fc8')\n",
        "        print(\"build model finished: %fs\" % (time.time() - start_time))\n",
        "        return network, conv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qCQ2gM-nLvFl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Config"
      ]
    },
    {
      "metadata": {
        "id": "DNy6L1XGLvFn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#config = edict()\n",
        "#config.TRAIN = edict()\n",
        "#config.VALID = edict()\n",
        "\n",
        "## Adam\n",
        "batch_size = 4\n",
        "lr_init = 1e-4\n",
        "beta1 = 0.9\n",
        "# config.TRAIN.batch_size = 2\n",
        "# config.TRAIN.lr_init = 1e-4\n",
        "# config.TRAIN.beta1 = 0.9\n",
        "\n",
        "\n",
        "## initialize G\n",
        "n_epoch_init = 0\n",
        "# config.TRAIN.n_epoch_init = 2\n",
        "#    config.TRAIN.lr_decay_init = 0.1\n",
        "#   config.TRAIN.decay_every_init = int(config.TRAIN.n_epoch_init / 2)\n",
        "\n",
        "## adversarial learning (SRGAN)\n",
        "n_epoch = 4\n",
        "lr_decay = 0.1\n",
        "decay_every = int(n_epoch / 2)\n",
        "# config.TRAIN.n_epoch = 2\n",
        "# config.TRAIN.lr_decay = 0.1\n",
        "# config.TRAIN.decay_every = int(config.TRAIN.n_epoch / 2)\n",
        "\n",
        "\n",
        "## train set location\n",
        "train_hr_img_path = 'data2017/DIV2K_train_HR/'\n",
        "train_lr_img_path = 'data2017/DIV2K_train_LR_bicubic/X4/'\n",
        "# config.TRAIN.hr_img_path = 'data2017/DIV2K_train_HR/'\n",
        "# config.TRAIN.lr_img_path = 'data2017/DIV2K_train_LR_bicubic/X4/'\n",
        "\n",
        "## test set location\n",
        "test_hr_img_path = 'data2017/DIV2K_valid_HR/'\n",
        "test_lr_img_path = 'data2017/DIV2K_valid_LR_bicubic/X4/'\n",
        "# config.VALID.hr_img_path = 'data2017/DIV2K_valid_HR/'\n",
        "# config.VALID.lr_img_path = 'data2017/DIV2K_valid_LR_bicubic/X4/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lFJw19KkLvFt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "ni = int(np.sqrt(batch_size))\n",
        "print(ni)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g1HTCoFELvFx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "9ot0czQbLvF0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_save_dir_ginit = 'samples/train_ginit'\n",
        "train_save_dir_gan = 'samples/train_gan'\n",
        "checkpoint_dir = 'checkpoint'\n",
        "tl.files.exists_or_mkdir(train_save_dir_ginit)\n",
        "tl.files.exists_or_mkdir(train_save_dir_gan)\n",
        "tl.files.exists_or_mkdir(checkpoint_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JUeFt_IBLvF-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_hr_img_list = sorted(tl.files.load_file_list(path=train_hr_img_path, regx='.*.png', printable=False))\n",
        "train_lr_img_list = sorted(tl.files.load_file_list(path=train_lr_img_path, regx='.*.png', printable=False))\n",
        "test_hr_img_list  = sorted(tl.files.load_file_list(path=test_hr_img_path,  regx='.*.png', printable=False))\n",
        "test_lr_img_list  = sorted(tl.files.load_file_list(path=test_lr_img_path,  regx='.*.png', printable=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4kgZgErLvGH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Load full training set\n",
        "train_hr_imgs = tl.vis.read_images(train_hr_img_list, path=train_hr_img_path, n_threads=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BEQKOJepLvGO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## train inference\n",
        "t_image = tf.placeholder('float32', [batch_size, 96, 96, 3], name='t_image_input_to_SRGAN_generator')\n",
        "t_target_image = tf.placeholder('float32', [batch_size, 384, 384, 3], name='t_target_name')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHLYlaUWLvGV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "net_g = SRGAN_g(t_image, is_train=True, reuse=False)\n",
        "net_d, logits_real = SRGAN_d(t_target_image, is_train=True, reuse=False)\n",
        "_, logits_fake = SRGAN_d(net_g.outputs, is_train=True, reuse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vnC9-jgWLvGa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "net_g.print_params(False)\n",
        "net_d.print_params(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uVPFHOS4LvGd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## vgg inference. 0, 1, 2, 3 BILINEAR NEAREST BICUBIC AREA\n",
        "t_target_image_224 = tf.image.resize_images(\n",
        "    t_target_image,\n",
        "    size=[224, 224],\n",
        "    method=0,\n",
        "    align_corners=False\n",
        ")\n",
        "\n",
        "t_predict_image_224 = tf.image.resize_images(\n",
        "    net_g.outputs,\n",
        "    size=[224,224],\n",
        "    method=0,\n",
        "    align_corners=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4eozMJgeLvGi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "net_vgg, vgg_target_emb = Vgg19_simple_api((t_target_image_224 + 1) / 2, reuse=False)\n",
        "_, vgg_predict_emb = Vgg19_simple_api((t_predict_image_224 + 1) / 2, reuse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nzE_CG-fLvGk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## test inference\n",
        "net_g_test = SRGAN_g(t_image, is_train=False, reuse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kapeu51SLvGo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Train ops\n",
        "d_loss1 = tl.cost.sigmoid_cross_entropy(logits_real, tf.ones_like(logits_real), name='d1')\n",
        "d_loss2 = tl.cost.sigmoid_cross_entropy(logits_fake, tf.zeros_like(logits_fake), name='d2')\n",
        "d_loss = d_loss1 + d_loss2\n",
        "\n",
        "g_gan_loss = 1e-3 * tl.cost.sigmoid_cross_entropy(logits_fake, tf.ones_like(logits_fake), name='g')\n",
        "mse_loss = tl.cost.mean_squared_error(net_g.outputs, t_target_image, is_mean=True)\n",
        "vgg_loss = 2e-6 * tl.cost.mean_squared_error(vgg_predict_emb.outputs, vgg_target_emb.outputs, is_mean=True)\n",
        "\n",
        "g_loss = mse_loss + vgg_loss + g_gan_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kGNjs0QZcFtr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir train_summary\n",
        "summary_dir = 'train_summary'\n",
        "tf.summary.scalar('g_loss', g_loss)\n",
        "tf.summary.scalar('d_loss', d_loss)\n",
        "summary_op = tf.summary.merge_all()\n",
        "summary_writer = tf.summary.FileWriter('train_summary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EyYIR-n6LvGt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "g_vars = tl.layers.get_variables_with_name('SRGAN_g', True, True)\n",
        "d_vars = tl.layers.get_variables_with_name('SRGAN_d', True, True)\n",
        "\n",
        "with tf.variable_scope('learning_rate'):\n",
        "    lr_v = tf.Variable(lr_init, trainable=False)\n",
        "## Pretrain\n",
        "g_optim_init = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(mse_loss, var_list=g_vars)\n",
        "## SRGAN\n",
        "g_optim = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
        "d_optim = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(d_loss, var_list=d_vars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L2QENsZAU2Is",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mode = 'srgan'\n",
        "#mode = 'evaluate'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vx6lPecjLvG0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Restore Model\n",
        "config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.Session(config=config)\n",
        "tl.layers.initialize_global_variables(sess)\n",
        "if tl.files.load_and_assign_npz(sess=sess, name=checkpoint_dir + '/g_{}.npz'.format('srgan'), network=net_g) is False:\n",
        "    tl.files.load_and_assign_npz(sess=sess, name=checkpoint_dir + '/g_{}_init.npz'.format('srgan'), network=net_g)\n",
        "tl.files.load_and_assign_npz(sess=sess, name=checkpoint_dir + '/d_{}.npz'.format('srgan'), network=net_d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nBsizJIOLvG5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Load VGG\n",
        "vgg19_npy_path = \"vgg19.npy\"\n",
        "if not os.path.isfile(vgg19_npy_path):\n",
        "    print(\"Please download vgg19.npz from : https://github.com/machrisaa/tensorflow-vgg\")\n",
        "else:\n",
        "    npz = np.load(vgg19_npy_path, encoding='latin1').item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aK7372JQLvG9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "params = []\n",
        "for val in sorted(npz.items()):\n",
        "    W = np.asarray(val[1][0])\n",
        "    b = np.asarray(val[1][1])\n",
        "    print(\"  Loading %s: %s, %s\" % (val[0], W.shape, b.shape))\n",
        "    params.extend([W, b])\n",
        "tl.files.assign_params(sess, params, net_vgg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MjV8Y3-6LvHB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### training\n",
        "#sample_imgs = train_hr_imgs[:batch_size]\n",
        "sample_imgs = tl.vis.read_images(train_hr_img_list[0:batch_size], path=train_hr_img_path, n_threads=32) # if no pre-load train set\n",
        "\n",
        "sample_imgs_384 = tl.prepro.threading_data(sample_imgs, fn=crop_sub_img_fn, is_random=False)\n",
        "print('sample HR sub-image:', sample_imgs_384.shape, sample_imgs_384.min(), sample_imgs_384.max())\n",
        "\n",
        "sample_imgs_96 = tl.prepro.threading_data(sample_imgs_384, fn=downsample_fn)\n",
        "print('sample LR sub-image:', sample_imgs_96.shape, sample_imgs_96.min(), sample_imgs_96.max())\n",
        "\n",
        "tl.vis.save_images(sample_imgs_96,  [ni, ni], train_save_dir_ginit + '/_train_sample_96.png')\n",
        "tl.vis.save_images(sample_imgs_384, [ni, ni], train_save_dir_ginit + '/_train_sample_384.png')\n",
        "tl.vis.save_images(sample_imgs_96,  [ni, ni], train_save_dir_gan + '/_train_sample_96.png')\n",
        "tl.vis.save_images(sample_imgs_384, [ni, ni], train_save_dir_gan + '/_train_sample_384.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mynSscpxCUX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Restore Model\n",
        "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
        "tl.layers.initialize_global_variables(sess)\n",
        "if tl.files.load_and_assign_npz(sess=sess, name=checkpoint_dir + '/g_{}.npz'.format('srgan'), network=net_g) is False:\n",
        "    tl.files.load_and_assign_npz(sess=sess, name=checkpoint_dir + '/g_{}_init.npz'.format('srgan'), network=net_g)\n",
        "tl.files.load_and_assign_npz(sess=sess, name=checkpoint_dir + '/d_{}.npz'.format('srgan'), network=net_d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O5dihOTSLvHG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### initialize G\n",
        "## fixed learning rate\n",
        "sess.run(tf.assign(lr_v, lr_init))\n",
        "print(' ** fixed learning rate: %f (for init G)' % lr_init)\n",
        "for epoch in range(0, n_epoch_init+1):\n",
        "    epoch_time = time.time()\n",
        "    total_mse_loss, n_iter = 0, 0\n",
        "    \n",
        "    random.shuffle(train_hr_img_list)\n",
        "    #for idx in range(0, len(train_hr_imgs), batch_size):\n",
        "    #    step_time = time.time()\n",
        "    #    b_img_384 = tl.prepro.threading_data(train_hr_imgs[idx:idx + batch_size], fn=crop_sub_imgs_fn, is_random=True)\n",
        "    #    b_img_96  = tl.prepro.threading_data(b_imgs_384, fn=downscale_fn)\n",
        "    \n",
        "    for idx in range(0, len(train_hr_img_list), batch_size):\n",
        "    #for idx in range(0, 10, batch_size):\n",
        "        step_time = time.time()\n",
        "        b_imgs_list = train_hr_img_list[idx : idx + batch_size]\n",
        "        b_imgs = tl.prepro.threading_data(b_imgs_list, fn=get_imgs_fn, path=train_hr_img_path)\n",
        "        b_imgs_384 = tl.prepro.threading_data(b_imgs, fn=crop_sub_img_fn, is_random=True)\n",
        "        b_imgs_96 = tl.prepro.threading_data(b_imgs_384, fn=downsample_fn)\n",
        "    \n",
        "        errM, _ = sess.run([mse_loss, g_optim_init], {t_image: b_imgs_96, t_target_image: b_imgs_384})\n",
        "        print(\"Epoch [%2d/%2d] %4d time: %4.4fs, mse: %.8f \" % (epoch, n_epoch_init, n_iter, time.time() - step_time, errM))\n",
        "        total_mse_loss += errM\n",
        "        n_iter += 1\n",
        "    log = \"[*] Epoch: [%2d/%2d] time: %4.4fs, mse: %.8f\" % (epoch, n_epoch_init, time.time() - epoch_time, total_mse_loss / n_iter)\n",
        "    print(log)\n",
        "    \n",
        "    if (epoch != 0) and (epoch % 10 == 0):\n",
        "        out = sess.run(net_g_test.outputs, {t_image: sample_imgs_96})  #; print('gen sub-image:', out.shape, out.min(), out.max())\n",
        "        print(\"[*] save images\")\n",
        "        tl.vis.save_images(out, [ni, ni], train_save_dir_ginit + '/train_%d.png' % epoch)\n",
        "\n",
        "    ## save model\n",
        "    if (epoch != 0) and (epoch % 10 == 0):\n",
        "        tl.files.save_npz(net_g.all_params, name=checkpoint_dir + '/g_train_init.npz', sess=sess)\n",
        "\n",
        "### save at end\n",
        "tl.files.save_npz(net_g.all_params, name=checkpoint_dir + '/g_train_init.npz', sess=sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ja8krXdxLvHL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Train GAN\n",
        "for epoch in range(0, n_epoch+1):\n",
        "    if epoch != 0 and (epoch % decay_every == 0):\n",
        "        new_lr_decay = lr_decay ** (epoch // decay_every)\n",
        "        sess.run(tf.assign(lr_v, lr_init * new_lr_decay))\n",
        "        log = \" ** new learning rate: %f (for GAN)\" % (lr_init * new_lr_decay)\n",
        "        print(log)\n",
        "    elif epoch == 0:\n",
        "        sess.run(tf.assign(lr_v, lr_init))\n",
        "        log = \" ** init lr: %f  decay_every_init: %d, lr_decay: %f (for GAN)\" % (lr_init, decay_every, lr_decay)\n",
        "        print(log)\n",
        "    \n",
        "    epoch_time = time.time()\n",
        "    total_d_loss, total_g_loss, n_iter = 0, 0, 0\n",
        "    \n",
        "    #for idx in range(0, len(train_hr_imgs), batch_size):\n",
        "    #    step_time = time.time()\n",
        "    #    b_imgs_384 = tl.prepro.threading_data(train_hr_imgs[idx:idx + batch_size], fn=crop_sub_imgs_fn, is_random=True)\n",
        "    #    b_imgs_96 = tl.prepro.threading_data(b_imgs_384, fn=downsample_fn)\n",
        "    \n",
        "    for idx in range(0, len(train_hr_img_list), batch_size):\n",
        "    #for idx in range(0, 10, batch_size):\n",
        "        step_time = time.time()\n",
        "        b_imgs_list = train_hr_img_list[idx : idx + batch_size]\n",
        "        b_imgs = tl.prepro.threading_data(b_imgs_list, fn=get_imgs_fn, path=train_hr_img_path)\n",
        "        b_imgs_384 = tl.prepro.threading_data(b_imgs, fn=crop_sub_img_fn, is_random=True)\n",
        "        b_imgs_96 = tl.prepro.threading_data(b_imgs_384, fn=downsample_fn)\n",
        "    \n",
        "        ## update D\n",
        "        errD, _ = sess.run([d_loss, d_optim], {t_image: b_imgs_96, t_target_image: b_imgs_384})\n",
        "        ## update G\n",
        "        errG, errM, errV, errA, _, summary = sess.run([g_loss, mse_loss, vgg_loss, g_gan_loss, g_optim, summary_op], {t_image: b_imgs_96, t_target_image: b_imgs_384})\n",
        "        print(\"Epoch [%2d/%2d] %4d time: %4.4fs, d_loss: %.8f g_loss: %.8f (mse: %.6f vgg: %.6f adv: %.6f)\" %\n",
        "                (epoch, n_epoch, n_iter, time.time() - step_time, errD, errG, errM, errV, errA))\n",
        "        total_d_loss += errD\n",
        "        total_g_loss += errG\n",
        "        n_iter += 1\n",
        "        \n",
        "        summary_writer.add_summary(summary, epoch)\n",
        "    \n",
        "    log = \"[*] Epoch: [%2d/%2d] time: %4.4fs, d_loss: %.8f g_loss: %.8f\" % (epoch, n_epoch, time.time() - epoch_time, total_d_loss / n_iter, total_g_loss / n_iter)\n",
        "    print(log)\n",
        "    \n",
        "    if (epoch != 0) and (epoch % 10 == 0):\n",
        "        out = sess.run(net_g_test.outputs, {t_image: sample_imgs_96})  #; print('gen sub-image:', out.shape, out.min(), out.max())\n",
        "        print(\"[*] save images\")\n",
        "        tl.vis.save_images(out, [ni, ni], train_save_dir_gan + '/train_%d.png' % epoch)\n",
        "\n",
        "    ## save model\n",
        "    if (epoch != 0) and (epoch % 10 == 0):\n",
        "        tl.files.save_npz(net_g.all_params, name=checkpoint_dir + '/g_train.npz', sess=sess)\n",
        "        tl.files.save_npz(net_d.all_params, name=checkpoint_dir + '/d_train.npz', sess=sess)\n",
        "\n",
        "### save at end\n",
        "tl.files.save_npz(net_g.all_params, name=checkpoint_dir + '/g_train.npz', sess=sess)\n",
        "tl.files.save_npz(net_d.all_params, name=checkpoint_dir + '/d_train.npz', sess=sess)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a5mjTxFsLvHQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lSPPS4_3LvHb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ]
    },
    {
      "metadata": {
        "id": "XeBIqsa9LvHc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "save_dir = 'samples/test'\n",
        "checkpoint_dir = 'checkpoint'\n",
        "tl.files.exists_or_mkdir(save_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIxarQjNLvHh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test_hr_img_list = sorted(tl.files.load_file_list(path=test_hr_img_path, regx='.*.png', printable=False))\n",
        "test_lr_img_list = sorted(tl.files.load_file_list(path=test_lr_img_path, regx='.*.png', printable=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KTp4FfjeLvHm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test_lr_imgs = tl.vis.read_images(test_lr_img_list, path=test_lr_img_path, n_threads=32)\n",
        "test_hr_imgs = tl.vis.read_images(test_hr_img_list, path=test_hr_img_path, n_threads=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hejb5NTsLvHp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "imid = 64\n",
        "test_lr_img = test_lr_imgs[imid]\n",
        "test_hr_img = test_hr_imgs[imid]\n",
        "test_lr_img = (test_lr_img / 127.5) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "24-UuW_8LvHt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "size = test_lr_img.shape\n",
        "print(size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PMNQ10xrLvHw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "t_image = tf.placeholder('float32', [1, None, None, 3], name='input_image')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YZFPYGIjLvH2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "net_g = SRGAN_g(t_image, is_train=False, reuse=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aGwWc3pMLvH8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## Restore G\n",
        "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
        "tl.layers.initialize_global_variables(sess)\n",
        "tl.files.load_and_assign_npz(sess=sess, name=checkpoint_dir + '/g_train.npz', network=net_g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g6e7z6qoLvH_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for test_lr_img in test_lr_imgs:\n",
        "    start_time = time.time()\n",
        "    size = test_lr_img.shape\n",
        "    test_lr_img = (test_lr_img / 127.5) - 1\n",
        "    out = sess.run(net_g.outputs, {t_image: [test_lr_img]})\n",
        "    print(\"took: %4.4fs\" % (time.time() - start_time))\n",
        "    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
        "    print(\"[*] save images\")\n",
        "    tl.vis.save_image(out[0], save_dir + '/test_gen_{}.png'.format(i))\n",
        "    tl.vis.save_image(test_lr_img, save_dir + '/test_lr_{}.png'.format(i))\n",
        "    tl.vis.save_image(test_hr_imgs[i], save_dir + '/test_hr_{}.png'.format(i))\n",
        "    out_bicu = scipy.misc.imresize(test_lr_img, [size[0] * 4, size[1] * 4], interp='bicubic', mode=None)\n",
        "    tl.vis.save_image(out_bicu, save_dir + '/test_bicubic_{}.png'.format(i))\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wq96zwacJCQ3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls samples/test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d6zLcj8rLvIo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!zip -r srgan_out_4.zip samples/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3UgaZavds0j-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('srgan_out_2.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DFadATrFtFiq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://uofi.box.com/shared/static/kfahv87nfe8ax910l85dksyl2q212voc.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oT7XhzY9ufsp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kjyLiMqpurWm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip kfahv87nfe8ax910l85dksyl2q212voc.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X2NKm3JAuwRf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xXmFq5lvwEcQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip set5_hr_4.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VrlHOHi-uxK9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test_hr_img_list = sorted(tl.files.load_file_list(path='set5_hr_4', regx='.*.png', printable=False))\n",
        "test_lr_img_list = sorted(tl.files.load_file_list(path='set5_lr_4', regx='.*.png', printable=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eLpeqN0vwnTT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test_lr_imgs = tl.vis.read_images(test_lr_img_list, path='set5_lr_4', n_threads=32)\n",
        "test_hr_imgs = tl.vis.read_images(test_hr_img_list, path='set5_hr_4', n_threads=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8BBQ_8gcwrdN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for test_lr_img in test_lr_imgs:\n",
        "  test_lr_img = (test_lr_img / 127.5) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RlmGaX25xByp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for test_lr_img in test_lr_imgs[:10]:\n",
        "    start_time = time.time()\n",
        "    out = sess.run(net_g.outputs, {t_image: [test_lr_img]})\n",
        "    print(\"took: %4.4fs\" % (time.time() - start_time))\n",
        "    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
        "    print(\"[*] save images\")\n",
        "    tl.vis.save_image(out[0], save_dir + '/test_gen_{}.png'.format(i))\n",
        "    tl.vis.save_image(test_lr_img, save_dir + '/test_lr_{}.png'.format(i))\n",
        "    tl.vis.save_image(test_hr_img, save_dir + '/test_hr_{}.png'.format(i))\n",
        "    out_bicu = scipy.misc.imresize(test_lr_img, [size[0] * 4, size[1] * 4], interp='bicubic', mode=None)\n",
        "    tl.vis.save_image(out_bicu, save_dir + '/test_bicubic_{}.png'.format(i))\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9JbFVDPoxcc_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#!rm -rf samples/test/\n",
        "!zip -r srgan_out_set5_3.zip samples/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ld9biyOzxsx2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('srgan_out_set5_2.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uP4-G5_dxxzS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://googledrive.github.io/PyDrive/docs/build/html/index.html\n",
        "\n",
        "# 2. Create & upload a file text file.\n",
        "#uploaded = drive.CreateFile({'title': 'Sample upload.txt'})\n",
        "#uploaded.SetContentString('Sample upload file content')\n",
        "#uploaded.Upload()\n",
        "#print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "# 3. Load a file by ID and print its contents.\n",
        "#downloaded = drive.CreateFile({'id': uploaded.get('id')})\n",
        "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZFNo52ze0f3N",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBwI8if-2GPw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tPMMfkGn2Iqc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Upload the file to Drive. See:\n",
        "#\n",
        "# https://developers.google.com/drive/v3/reference/files/create\n",
        "# https://developers.google.com/drive/v3/web/manage-uploads\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "file_metadata = {\n",
        "  'name': 'srgan_out_4.zip',\n",
        "  'mimeType': 'application/zip'\n",
        "}\n",
        "media = MediaFileUpload('srgan_out_4.zip', \n",
        "                        mimetype='application/zip',\n",
        "                        resumable=True)\n",
        "created = drive_service.files().create(body=file_metadata,\n",
        "                                       media_body=media,\n",
        "                                       fields='id').execute()\n",
        "print('File ID: {}'.format(created.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xBymhEry2X9T",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KyPK7QZI2ax0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}