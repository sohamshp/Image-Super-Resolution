{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trial_1.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "BpukvtG9Exfy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import csv\n",
        "import os\n",
        "import glob\n",
        "import h5py\n",
        "import scipy.misc\n",
        "import scipy.ndimage\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eT29QRWCFa26",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xKMr4mONE_LE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FUln4M8oLGF8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l\n",
        "#!zip -r dataset.zip DIV2K_train_HR.zip DIV2K_train_LR_bicubic_X4.zip DIV2K_valid_HR.zip DIV2K_valid_LR_bicubic_X4.zip Test.zip Train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ORgrlkxz6Z16",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "agIb7sPn6a_Z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g_oeL-MK6azV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "# Work around misordering of STREAM and STDIN in Jupyter.\n",
        "# https://github.com/jupyter/notebook/issues/3159\n",
        "prompt = !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass(prompt[0] + '\\n\\nEnter verification code: ')\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Yp-lWDd6fOu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "print('Files in Drive:')\n",
        "!ls drive/\n",
        "\n",
        "# Create a file in Drive.\n",
        "!echo \"This newly created file will appear in your Drive file list.\" > drive/created.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kmT2rzFYMpvR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OHEgjxcUHy8Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf Train Test\n",
        "!unzip Train.zip\n",
        "!unzip Test.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ru1lG83HKe5l",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9v0peyBofRIV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## Global Var.\n",
        "g_epoch = 300\n",
        "g_batch_size = 128\n",
        "g_image_size = 33\n",
        "g_label_size = 21\n",
        "g_learn_rate = 1e-4 # default: 1e-4\n",
        "g_color_dim = 3\n",
        "g_scale = 3\n",
        "g_checkpoint_dir = \"checkpoint_srcnn\"\n",
        "g_output_dir = \"output_srcnn\"\n",
        "g_extract_stride = 14\n",
        "g_test_extract_stride = g_label_size\n",
        "g_is_train = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9TIEaxZ2f23",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf checkpoint_srcnn output_srcnn\n",
        "!mkdir checkpoint_srcnn\n",
        "!mkdir output_srcnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lNl4RxKQKvEE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KYx23qlW003M",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "g_counter = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EogHCmSr04Iy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Network Model\n",
        "\n",
        "# input and label images\n",
        "images = tf.placeholder(tf.float32, [None, g_image_size, g_image_size, g_color_dim], name='images')\n",
        "labels = tf.placeholder(tf.float32, [None, g_label_size, g_label_size, g_color_dim], name='labels')\n",
        "\n",
        "# weights and biases\n",
        "weights = {\n",
        "    'w1': tf.Variable(tf.random_normal([9, 9, 3, 64], mean=0, stddev=1e-3), name='w1'),\n",
        "    'w2': tf.Variable(tf.random_normal([1, 1, 64, 32], mean=0, stddev=1e-3), name='w2'),\n",
        "    'w3': tf.Variable(tf.random_normal([5, 5, 32, 3], mean=0, stddev=1e-3), name='w3')\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.zeros([64]), name='b1'),\n",
        "    'b2': tf.Variable(tf.zeros([32]), name='b2'),\n",
        "    'b3': tf.Variable(tf.zeros([1]), name='b3')\n",
        "}\n",
        "\n",
        "# Layers\n",
        "conv1 = tf.nn.relu(tf.nn.conv2d(images, weights['w1'], strides=[1, 1, 1, 1], padding='VALID') + biases['b1'])\n",
        "\n",
        "conv2 = tf.nn.relu(tf.nn.conv2d(conv1, weights['w2'], strides=[1, 1, 1, 1], padding='VALID') + biases['b2'])\n",
        "\n",
        "conv3 = tf.nn.conv2d(conv2, weights['w3'], strides=[1, 1, 1, 1], padding='VALID') + biases['b3']\n",
        "\n",
        "# Output\n",
        "pred = conv3\n",
        "\n",
        "# Loss function\n",
        "loss = tf.reduce_mean(tf.square(labels - pred))\n",
        "\n",
        "# Saver\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dub3fcrm09tY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tf.summary.scalar('loss', loss)\n",
        "merged = tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-54lz_s-dXG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir train_summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9CIMtHOc1uR9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_writer = tf.summary.FileWriter('train_summary')\n",
        "#test_writer = tf.summary.FileWriter('test_summary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3rIr_Q9y2Iqf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Checkpointing functions - Save and Load\n",
        "\n",
        "def save(sess, checkpoint_dir, scale, step):\n",
        "\n",
        "    print(\"Saving checkpoint - step [{}]\".format(step))\n",
        "    model_name = \"SRCNN.model\"\n",
        "    model_dir = \"%s_%s_%s\" % (\"srcnn\", \"scale\", scale)\n",
        "    checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    saver.save(sess, os.path.join(checkpoint_dir, model_dir), global_step=step)\n",
        "\n",
        "\n",
        "def load(sess, checkpoint_dir, scale):\n",
        "    \"\"\"\n",
        "    Load the checkpoint.\n",
        "    According to the scale, read different folder to load the models.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\" [*] Reading checkpoints...\")\n",
        "    model_dir = \"%s_%s_%s\" % (\"srcnn\", \"scale\", scale)\n",
        "    checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
        "\n",
        "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
        "        saver.restore(sess, os.path.join(checkpoint_dir, ckpt_name))\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vd0NTt4B2dbj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Prep data from training\n",
        "\n",
        "def modcrop(image, scale=3):\n",
        "    \"\"\"\n",
        "    In order to scale down and up the original image, the first thing needed to\n",
        "    do is to have no remainder while scaling operation.\n",
        "    We need to find modulo of height (and width) and scale factor.\n",
        "    Then, subtract the modulo from height (and width) of original image size.\n",
        "    There would be no remainder even after scaling operation.\n",
        "    \"\"\"\n",
        "\n",
        "    if len(image.shape) == 3:\n",
        "        h, w, _ = image.shape\n",
        "        h = h - np.mod(h, scale)\n",
        "        w = w - np.mod(w, scale)\n",
        "        image = image[0:h, 0:w, :]\n",
        "    else:\n",
        "        h, w = image.shape\n",
        "        h = h - np.mod(h, scale)\n",
        "        w = w - np.mod(w, scale)\n",
        "        image = image[0:h, 0:w]\n",
        "\n",
        "    return image\n",
        "        \n",
        "\n",
        "def input_setup(sess):\n",
        "    preprocessed_folder = \"preprocessed_scale_{}\".format(g_scale)\n",
        "    label_data_ext = \"*_org.bmp\"\n",
        "    input_data_ext = \"*_bicubic_scale_{}.bmp\".format(g_scale)\n",
        "    \n",
        "    data_dir = os.path.join('Train', preprocessed_folder)\n",
        "    label_data = glob.glob(os.path.join(data_dir, label_data_ext))\n",
        "    input_data = glob.glob(os.path.join(data_dir, input_data_ext))\n",
        "    \n",
        "    label_data = sorted(label_data)\n",
        "    input_data = sorted(input_data)\n",
        "    \n",
        "    sub_input_sequence = []\n",
        "    sub_label_sequence = []\n",
        "    \n",
        "    padding = int(abs(g_image_size - g_label_size) / 2) # 6\n",
        "    \n",
        "    for i in range(len(input_data)):\n",
        "        # Preprocess the input images\n",
        "        #input_, label_ = preprocess(input_data[i], mean, stddev, g_scale)\n",
        "        \n",
        "        #input_ = modcrop(scipy.misc.imread(input_data[i], flatten=True, mode='YCbCr').astype(np.float64), g_scale) # / 255.\n",
        "        #label_ = modcrop(scipy.misc.imread(label_data[i], flatten=True, mode='YCbCr').astype(np.float64), g_scale) # / 255.\n",
        "        \n",
        "        input_ = modcrop(scipy.misc.imread(input_data[i], mode='RGB'), g_scale) # / 255.\n",
        "        label_ = modcrop(scipy.misc.imread(label_data[i], mode='RGB'), g_scale) # / 255.\n",
        "        \n",
        "        #plt.imshow(label_)\n",
        "        \n",
        "        input_ = input_ / 255\n",
        "        label_ = label_ / 255\n",
        "        \n",
        "        #plt.imshow(label_)\n",
        "        \n",
        "        #input_ *= 255\n",
        "        #label_ *= 255\n",
        "        \n",
        "        if len(input_.shape) == 3:\n",
        "            h, w, _ = input_.shape\n",
        "        else:\n",
        "            h, w = input_.shape\n",
        "\n",
        "        # Crop the input images\n",
        "        for x in range(0, h-g_image_size+1, g_extract_stride):\n",
        "            for y in range(0, w-g_image_size+1, g_extract_stride):\n",
        "                sub_input = input_[x:x+g_image_size, y:y+g_image_size] # [33 x 33]\n",
        "                sub_label = label_[x+padding:x+padding+g_label_size, y+padding:y+padding+g_label_size] # [21 x 21]\n",
        "\n",
        "                #plt.imshow(sub_label)\n",
        "                \n",
        "                # Make channel value\n",
        "                sub_input = sub_input.reshape([g_image_size, g_image_size, g_color_dim])\n",
        "                sub_label = sub_label.reshape([g_label_size, g_label_size, g_color_dim])\n",
        "\n",
        "                #plt.imshow(sub_label)\n",
        "                \n",
        "                sub_input_sequence.append(sub_input)\n",
        "                sub_label_sequence.append(sub_label)\n",
        "    \n",
        "    arrdata = np.asarray(sub_input_sequence) # [?, 33, 33, 1]\n",
        "    arrlabel = np.asarray(sub_label_sequence) # [?, 21, 21, 1]\n",
        "\n",
        "    savepath = 'checkpoint_srcnn/train.h5'\n",
        "    with h5py.File(savepath, 'w') as hf:\n",
        "        hf.create_dataset('data', data=arrdata)\n",
        "        hf.create_dataset('label', data=arrlabel)\n",
        "\n",
        "\n",
        "def read_data(path):\n",
        "    with h5py.File(path, 'r') as hf:\n",
        "        data = np.array(hf.get('data'))\n",
        "        label = np.array(hf.get('label'))\n",
        "\n",
        "    return data, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yXSOobKy2wEC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Training\n",
        "def train_runner(g_counter):\n",
        "    with tf.Session() as sess:\n",
        "        input_setup(sess)\n",
        "        print(\"input done.\")\n",
        "        data_dir = os.path.join('./{}'.format(g_checkpoint_dir), \"train.h5\")\n",
        "        train_data, train_label = read_data(data_dir)\n",
        "\n",
        "        ###\n",
        "        '''\n",
        "        var_list_1 = [weights['w1'], weights['w2'], biases['b1'], biases['b2']]\n",
        "        var_list_2 = [weights['w3'], biases['b3']]\n",
        "        \n",
        "        train_op_1 = tf.train.AdamOptimizer(g_learn_rate).minimize(loss, var_list=var_list_1)\n",
        "        train_op_2 = tf.train.AdamOptimizer(g_learn_rate/10.).minimize(loss, var_list=var_list_2)\n",
        "        \n",
        "        train_op = tf.group(train_op_1, train_op_2)\n",
        "        '''\n",
        "        \n",
        "        ###\n",
        "        #'''\n",
        "        var_list__1 = [weights['w1'], weights['w2'], biases['b1'], biases['b2']]\n",
        "        var_list__2 = [weights['w3'], biases['b3']]\n",
        "        \n",
        "        opt_1 = tf.train.AdamOptimizer(g_learn_rate)\n",
        "        opt_2 = tf.train.AdamOptimizer(g_learn_rate/10.)\n",
        "        \n",
        "        grads = tf.gradients(loss, var_list__1 + var_list__2)\n",
        "        grads_1 = grads[:len(var_list__1)]\n",
        "        grads_2 = grads[len(var_list__1):]\n",
        "        \n",
        "        train_op__1 = opt_1.apply_gradients(zip(grads_1, var_list__1))\n",
        "        train_op__2 = opt_2.apply_gradients(zip(grads_2, var_list__2))\n",
        "        \n",
        "        train_op = tf.group(train_op__1, train_op__2)\n",
        "        #'''\n",
        "        \n",
        "        ###\n",
        "        #train_op = tf.train.AdamOptimizer(g_learn_rate).minimize(loss)\n",
        "        \n",
        "        \n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        iter_counter = 0\n",
        "        avg_loss = 0\n",
        "        avg_50_loss = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        if load(sess, g_checkpoint_dir, g_scale):\n",
        "            print('Checkpoint load SUCCESS.')\n",
        "        else:\n",
        "            print('Checkpoint load FAILED.')\n",
        "\n",
        "        for ep in range(g_epoch):\n",
        "            batch_idxs = len(train_data) // g_batch_size\n",
        "            print(len(train_data) ,batch_idxs)\n",
        "            print(g_batch_size)\n",
        "            shuffled_data = list(zip(train_data, train_label))\n",
        "            random.shuffle(shuffled_data)\n",
        "            train_data, train_label = zip(*shuffled_data)\n",
        "\n",
        "            for idx in range(0, batch_idxs):\n",
        "                iter_counter += 1\n",
        "                batch_images = train_data[idx*g_batch_size : (idx+1)*g_batch_size]\n",
        "                batch_labels = train_label[idx*g_batch_size : (idx+1)*g_batch_size]\n",
        "\n",
        "                _, err, summary = sess.run([train_op, loss, merged], feed_dict={images: batch_images, labels: batch_labels})\n",
        "                g_counter += 1\n",
        "                avg_loss += err\n",
        "                avg_50_loss += err\n",
        "\n",
        "                train_writer.add_summary(summary, ep)\n",
        "                \n",
        "                if iter_counter % 10 == 0:\n",
        "                    print(\"Epoch: [%2d], step: [%2d], time: [%4.4f], loss: [%.8f]\" % ((ep+1), iter_counter, time.time()-start_time, err))\n",
        "                if iter_counter % 50 == 0:\n",
        "                    save(sess, g_checkpoint_dir, g_scale, iter_counter)\n",
        "                    print(\"==> Epoch: [%2d], avg. loss of 50 steps: [%.8f], avg. loss: [%.8f]\" % ((ep+1), avg_50_loss/50, avg_loss/iter_counter))\n",
        "                    avg_50_loss = 0\n",
        "                if g_counter % 100 == 0:\n",
        "                    test_runner(sess, g_counter)\n",
        "\n",
        "        save(sess, g_checkpoint_dir, g_scale, iter_counter)\n",
        "        print(\"==> Epoch: [%2d], avg. loss of 50 steps: [%.8f], avg. loss: [%.8f]\" % ((ep+1), avg_50_loss/50, avg_loss/iter_counter))\n",
        "        avg_50_loss = 0\n",
        "#train_runner()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xtKF96pW2yxe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Prep for testing\n",
        "\n",
        "def input_setup_test(sess, img_index):\n",
        "    preprocessed_folder = \"/preprocessed_scale_{}\".format(g_scale)\n",
        "    label_data_ext = \"*_org.bmp\"\n",
        "    input_data_ext = \"*_bicubic_scale_{}.bmp\".format(g_scale)\n",
        "    \n",
        "    data_dir = os.path.join(os.sep, (os.path.join(os.getcwd(), 'Test')), \"Set5\" + preprocessed_folder)\n",
        "    label_data = glob.glob(os.path.join(data_dir, label_data_ext))\n",
        "    input_data = glob.glob(os.path.join(data_dir, input_data_ext))\n",
        "    \n",
        "    input_data = sorted(input_data)\n",
        "    label_data = sorted(label_data)\n",
        "    \n",
        "    sub_input_sequence = []\n",
        "    sub_label_sequence = []\n",
        "    \n",
        "    padding = int(abs(g_image_size - g_label_size) / 2) # 6\n",
        "    \n",
        "    #input_ = modcrop(scipy.misc.imread(input_data[img_index], flatten=True, mode='YCbCr').astype(np.float64), g_scale) # / 255.\n",
        "    #label_ = modcrop(scipy.misc.imread(label_data[img_index], flatten=True, mode='YCbCr').astype(np.float64), g_scale) # / 255.\n",
        "    \n",
        "    input_ = modcrop(scipy.misc.imread(input_data[img_index], mode='RGB'), g_scale) # / 255.\n",
        "    label_ = modcrop(scipy.misc.imread(label_data[img_index], mode='RGB'), g_scale) # / 255.\n",
        "    \n",
        "    input_ = input_ / 255\n",
        "    label_ = label_ / 255\n",
        "    \n",
        "    #input_ *= 255\n",
        "    #label_ *= 255\n",
        "\n",
        "    if len(input_.shape) == 3:\n",
        "        h, w, _ = input_.shape\n",
        "    else:\n",
        "        h, w = input_.shape\n",
        "\n",
        "    # Crop the input images\n",
        "    # Numbers of sub-images in height and width of image are needed to compute merge operation.\n",
        "    nx = ny = 0\n",
        "    for x in range(0, h-g_image_size+1, g_test_extract_stride):\n",
        "        nx += 1; ny = 0\n",
        "        for y in range(0, w-g_image_size+1, g_test_extract_stride):\n",
        "            ny += 1\n",
        "            sub_input = input_[x:x+g_image_size, y:y+g_image_size] # [33 x 33]\n",
        "            sub_label = label_[x+padding:x+padding+g_label_size, y+padding:y+padding+g_label_size] # [21 x 21]\n",
        "\n",
        "            sub_input = sub_input.reshape([g_image_size, g_image_size, g_color_dim])\n",
        "            sub_label = sub_label.reshape([g_label_size, g_label_size, g_color_dim])\n",
        "\n",
        "            sub_input_sequence.append(sub_input)\n",
        "            sub_label_sequence.append(sub_label)\n",
        "    \n",
        "    print(\"Saving the original images... size: [{} x {}]\".format(g_test_extract_stride*nx, g_test_extract_stride*ny))\n",
        "    image_path = os.path.join(os.getcwd(), g_output_dir)\n",
        "    org_img_path = os.path.join(image_path, \"{}_test_org_img.png\".format(img_index))\n",
        "    bicubic_img_path = os.path.join(image_path, \"{}_test_bicubic_img.png\".format(img_index))\n",
        "    imsave(label_[padding:padding+g_test_extract_stride*nx, padding:padding+g_test_extract_stride*ny], org_img_path)\n",
        "    imsave(input_[padding:padding+g_test_extract_stride*nx, padding:padding+g_test_extract_stride*ny], bicubic_img_path)\n",
        "    \n",
        "    arrdata = np.asarray(sub_input_sequence) # [?, 33, 33, 1]\n",
        "    arrlabel = np.asarray(sub_label_sequence) # [?, 21, 21, 1]\n",
        "\n",
        "    savepath = os.path.join(os.getcwd(), 'checkpoint_srcnn/test.h5')\n",
        "    with h5py.File(savepath, 'w') as hf:\n",
        "        hf.create_dataset('data', data=arrdata)\n",
        "        hf.create_dataset('label', data=arrlabel)\n",
        "    \n",
        "    return nx, ny\n",
        "\n",
        "\n",
        "def merge(images, size):\n",
        "    h, w = images.shape[1], images.shape[2]\n",
        "    img = np.zeros((h*size[0], w*size[1], 1))\n",
        "    for idx, image in enumerate(images):\n",
        "        i = idx % size[1]\n",
        "        j = idx // size[1]\n",
        "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def psnr(img1, img2):\n",
        "    mse = np.square(img1 - img2)\n",
        "    mse = mse.mean()\n",
        "    psnr = 20*np.log10(255./(np.sqrt(mse)))\n",
        "    return psnr\n",
        "\n",
        "\n",
        "def imsave(image, path):\n",
        "    image = image*255\n",
        "    #output_image = scipy.misc.toimage(image, high=np.max(image), low=np.min(image), mode='L')\n",
        "    #output_image = scipy.misc.toimage(image, high=255, low=np.min(image), mode='L')\n",
        "    output_image = scipy.misc.toimage(image, high=255, low=0)\n",
        "    output_image.save(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i7l_9_2A21Tq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "### Testing\n",
        "\n",
        "def test_runner(sess, g_counter):\n",
        "    psnr_srcnn = []\n",
        "    psnr_bicubic = []\n",
        "    counter_arr = []\n",
        "    psnr_csv_row = []\n",
        "    \n",
        "    #with tf.Session() as sess:\n",
        "    #if load(sess, g_checkpoint_dir, g_scale):\n",
        "    #    print(\"Checkpoint load SUCCESS.\")\n",
        "    #else:\n",
        "    #    print(\"Checkpoint load FAILED.\")\n",
        "\n",
        "    for i in range(5):\n",
        "        nx, ny = input_setup_test(sess, i)\n",
        "        data_dir = os.path.join('./{}'.format(g_checkpoint_dir), \"test.h5\")\n",
        "        test_data, test_label = read_data(data_dir)\n",
        "        result = pred.eval({images: test_data, labels: test_label})\n",
        "        #print(np.array(result).shape)\n",
        "        n, w, h, _ = np.array(result).shape\n",
        "        result_0 = merge(np.reshape(result[:,:,:,0], [n,w,h,1]), [nx, ny])\n",
        "        result_1 = merge(np.reshape(result[:,:,:,1], [n,w,h,1]), [nx, ny])\n",
        "        result_2 = merge(np.reshape(result[:,:,:,2], [n,w,h,1]), [nx, ny])\n",
        "        #print(result_0.shape)\n",
        "        #print(result_1.shape)\n",
        "        #print(result_2.shape)\n",
        "        #result = result_0.squeeze()\n",
        "        #result = np.dstack((result_0.squeeze(), result_1.squeeze(), result_2.squeeze()))\n",
        "        w, h = result_0.squeeze().shape\n",
        "        #print(w, h)\n",
        "        result = np.zeros([w, h, 3])\n",
        "        result[:,:,0] = result_0.squeeze()\n",
        "        result[:,:,1] = result_1.squeeze()\n",
        "        result[:,:,2] = result_2.squeeze()\n",
        "        \n",
        "        #plt.imshow(result)\n",
        "        #plt.pause(0.05)\n",
        "\n",
        "        # Save output image\n",
        "        output_path = os.path.join(os.getcwd(), g_output_dir)\n",
        "        image_path = os.path.join(output_path, \"{}_test_img.png\".format(i))\n",
        "        imsave(result, image_path)\n",
        "\n",
        "        # PSNR\n",
        "        label_path = os.path.join(output_path, \"{}_test_org_img.png\".format(i))\n",
        "        bicubic_path = os.path.join(output_path, \"{}_test_bicubic_img.png\".format(i))\n",
        "\n",
        "        #bicubic_img = scipy.misc.imread(bicubic_path, flatten=True, mode='YCbCr').astype(np.float64)\n",
        "        bicubic_img = scipy.misc.imread(bicubic_path, mode='RGB')\n",
        "        #plt.imshow(bicubic_img)\n",
        "        #plt.pause(0.05)\n",
        "        \n",
        "        #label_img = scipy.misc.imread(label_path, flatten=True, mode='YCbCr').astype(np.float64)\n",
        "        label_img = scipy.misc.imread(label_path, mode='RGB')\n",
        "        #plt.imshow(label_img)\n",
        "        #plt.pause(0.05)\n",
        "        \n",
        "        #output_img = scipy.misc.imread(image_path, flatten=True, mode='YCbCr').astype(np.float64)\n",
        "        output_img = scipy.misc.imread(image_path, mode='RGB')\n",
        "        #plt.imshow(output_img)\n",
        "        #plt.pause(0.05)\n",
        "        \n",
        "        bicubic_psnr_value = psnr(label_img, bicubic_img)\n",
        "        srcnn_psnr_value = psnr(label_img, output_img)\n",
        "\n",
        "        print(\"Image {}: Bicubic PSNR: [{}]\".format(i+1, bicubic_psnr_value))\n",
        "        print(\"Image {}: SRCNN PSNR: [{}]\".format(i+1, srcnn_psnr_value))\n",
        "\n",
        "        psnr_srcnn.append(srcnn_psnr_value)\n",
        "        psnr_bicubic.append(bicubic_psnr_value)\n",
        "        counter_arr = [g_counter]\n",
        "    psnr_csv_row = counter_arr + psnr_srcnn + psnr_bicubic\n",
        "    avg = 0\n",
        "    for psnr_val in psnr_bicubic:\n",
        "        avg += psnr_val\n",
        "    avg /= len(psnr_bicubic)\n",
        "    print(\"Avg. PSNR Bicubic: [{}]\".format(avg))\n",
        "    \n",
        "    avg = 0\n",
        "    for psnr_val in psnr_srcnn:\n",
        "        avg += psnr_val\n",
        "    avg /= len(psnr_srcnn)\n",
        "    print(\"Avg. PSNR SRCNN: [{}]\".format(avg))\n",
        "    \n",
        "    csv_path = os.path.join(output_path, 'set5_psnr_validation.csv')\n",
        "    with open(csv_path, 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(psnr_csv_row)\n",
        "#test_runner()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sky5_Z1i23-7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_runner(g_counter)\n",
        "g_counter += 170*g_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P-er94e_1mx_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#g_counter=0 68340\n",
        "print(g_counter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z95PnHVdRUzc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls train_summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5KwGxWmz29wh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#!zip -r ckpt_3dim_col_rev_51000.zip checkpoint_srcnn\n",
        "!zip -r op_col_6800.zip output_srcnn\n",
        "#files.download('ckpt_3dim_col_rev_51000.zip')\n",
        "files.download('op_col_6800.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MTfwAXuR3e7c",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!cat output/set5_psnr_validation.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v2mxN73a5EwI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#files.download('output_srcnn/set5_psnr_validation.csv')\n",
        "files.download('ckpt_3dim_col_rev_34000.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aDWHa_pV66X1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf checkpoint_srcnn\n",
        "!mkdir checkpoint_srcnn\n",
        "!rm -rf output_srcnn\n",
        "!mkdir output_srcnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RTQ8uLtv77Wg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!zip -r output_ckpt_srcnn_f.zip output_srcnn checkpoint_srcnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbBta5j0K77B",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xt-pPbz6LUdP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "files.download('output_ckpt_srcnn_f.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ksyW67sxLX-L",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf output.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GxkUgmNlLz1r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!zip -r train1.zip Train/preprocessed_scale_3\n",
        "files.download('train1.zip')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AoeCqWdbdoG3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Image Preprocess code"
      ]
    },
    {
      "metadata": {
        "id": "mpfTtZOJzA1g",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install scikit-image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jFtsDheidsGL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import h5py\n",
        "import scipy.misc\n",
        "import scipy.ndimage\n",
        "import numpy as np\n",
        "from scipy import misc\n",
        "import skimage.transform as transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJvoyJdJekw7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def normalize_1(image):\n",
        "    image = image/image.max()\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PRmmLi3-ePJR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def modcrop_1(image, scale=3):\n",
        "    if len(image.shape) == 3:\n",
        "        h, w, _ = image.shape\n",
        "        h = h - np.mod(h, scale)\n",
        "        w = w - np.mod(w, scale)\n",
        "        image = image[0:h, 0:w, :]\n",
        "    else:\n",
        "        h, w = image.shape\n",
        "        h = h - np.mod(h, scale)\n",
        "        w = w - np.mod(w, scale)\n",
        "        image = image[0:h, 0:w]\n",
        "\n",
        "    return image  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b9ByfdMue0_A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def imread_1(path, is_grayscale=True):\n",
        "    if is_grayscale:\n",
        "        return scipy.misc.imread(path, flatten=True, mode='YCbCr').astype(np.float64)\n",
        "    else:\n",
        "        return scipy.misc.imread(path, mode='RGB')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R-9v1Xu1e_S3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def preprocess_1(path, mean=0, stddev=1e-3, scale=3):\n",
        "    # Read Image\n",
        "    input_ = imread_1(path, is_grayscale=False)\n",
        "\n",
        "    # Crop the suitable size to fit the scale\n",
        "    input_modcropped = modcrop_1(input_, scale)\n",
        "\n",
        "    # Normalization\n",
        "    label_ = normalize_1(input_modcropped)\n",
        "    #label_ = input_modcropped / 255\n",
        "\n",
        "    #input_ = scipy.ndimage.interpolation.zoom(label_, (1./scale), prefilter=False)\n",
        "    #input_ = scipy.ndimage.interpolation.zoom(input_, (scale/1.), prefilter=False)\n",
        "\n",
        "    #input_ = misc.imresize(label_, 1./scale, 'bicubic')  ### before\n",
        "    #input_ = misc.imresize(input_, float(scale), 'bicubic')\n",
        "    \n",
        "    input_ = transform.rescale(label_, 1./scale)\n",
        "    input_ = transform.rescale(input_, float(scale))\n",
        "    \n",
        "    return input_, label_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3v-KExkpf6tc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def imsave_1(image, path):\n",
        "    image = image*255\n",
        "    output_image = misc.toimage(image, high=np.max(image), low=np.min(image))\n",
        "    output_image.save(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rab7-sv3iewU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir Test/Set5/preprocessed_scale_2\n",
        "!mkdir Test/Set5/preprocessed_scale_4\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-japXzrLimJ3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sorted(os.listdir('Test/Set5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KvE1Zc23f9Wh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "scale = 3\n",
        "img_dir = 'Test/Set5'\n",
        "image_list = list(filter(lambda x: x[-3:] == 'bmp', os.listdir(img_dir)))\n",
        "preprocessed_dir = list(filter(lambda x: x[-3:] != 'bmp', sorted(os.listdir(img_dir))))[scale-2] # 0->2; 1->3; 2->4\n",
        "\n",
        "\n",
        "for image in image_list:\n",
        "    #print(image)\n",
        "    input_, label_ = preprocess_1(os.path.join(img_dir, image), 0.5, 1e-4, scale)\n",
        "    filename, ext = image.split('.')\n",
        "    imsave_1(label_, './{}/{}_org.{}'.format(os.path.join(img_dir, preprocessed_dir), filename, ext))\n",
        "    imsave_1(input_, './{}/{}_bicubic_scale_{}.{}'.format(os.path.join(img_dir, preprocessed_dir), filename, scale, ext))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RW9FoDqajr8F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls Train/preprocessed_scale_3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H82RA1pokTWQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls Test/Set5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p6XS1lDfdqGU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!cp Test/Set5/baby_GT.bmp Test/Set5/preprocessed_scale_3/baby_GT_col.bmp\n",
        "!cp Test/Set5/bird_GT.bmp Test/Set5/preprocessed_scale_3/bird_GT_col.bmp\n",
        "!cp Test/Set5/butterfly_GT.bmp Test/Set5/preprocessed_scale_3/butterfly_GT_col.bmp\n",
        "!cp Test/Set5/head_GT.bmp Test/Set5/preprocessed_scale_3/head_GT_col.bmp\n",
        "!cp Test/Set5/woman_GT.bmp Test/Set5/preprocessed_scale_3/woman_GT_col.bmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XbNvZB-xedJy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls Test/Set5/preprocessed_scale_2/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L9OgDqXUx5Bb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!zip -r t3.zip Test/Set5/preprocessed_scale_3\n",
        "files.download('t3.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J1Gki9ASx-ih",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "files.download('pre3.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ltmCJYPPTu1N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### OpenCV image downsampler"
      ]
    },
    {
      "metadata": {
        "id": "ctSk8lLcTuWe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/wqi/img-downsampler/master/downsample.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KLRW8wtCTzyj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s02iOPCax12o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# View TF Graph"
      ]
    },
    {
      "metadata": {
        "id": "X_jHdn-6x4d9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output, Image, display, HTML\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
        "    strip_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = strip_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        if n.op == 'Const':\n",
        "            tensor = n.attr['value'].tensor\n",
        "            size = len(tensor.tensor_content)\n",
        "            if size > max_const_size:\n",
        "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
        "    return strip_def\n",
        "\n",
        "def show_graph(graph_def, max_const_size=32):\n",
        "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
        "    if hasattr(graph_def, 'as_graph_def'):\n",
        "        graph_def = graph_def.as_graph_def()\n",
        "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
        "    code = \"\"\"\n",
        "        <script>\n",
        "          function load() {{\n",
        "            document.getElementById(\"{id}\").pbtxt = {data};\n",
        "          }}\n",
        "        </script>\n",
        "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "        <div style=\"height:600px\">\n",
        "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "        </div>\n",
        "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "\n",
        "    iframe = \"\"\"\n",
        "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "    \"\"\".format(code.replace('\"', '&quot;'))\n",
        "    display(HTML(iframe))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zgJMSnyWx5pU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Create a sample tensor\"\"\"\n",
        "#sample_placeholder= tf.placeholder(dtype=tf.float32) \n",
        "\"\"\"Show it\"\"\"\n",
        "graph_def = tf.get_default_graph().as_graph_def()\n",
        "show_graph(graph_def)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "taU_yc_WOrog",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LqAY5Ym8Orlg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9FzesWGrOriQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IiInplvQOrfT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Upload the file to Drive. See:\n",
        "#\n",
        "# https://developers.google.com/drive/v3/reference/files/create\n",
        "# https://developers.google.com/drive/v3/web/manage-uploads\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "file_metadata = {\n",
        "  'name': 'dataset.zip',\n",
        "  'mimeType': 'application/zip'\n",
        "}\n",
        "media = MediaFileUpload('dataset.zip', \n",
        "                        mimetype='application/zip',\n",
        "                        resumable=True)\n",
        "created = drive_service.files().create(body=file_metadata,\n",
        "                                       media_body=media,\n",
        "                                       fields='id').execute()\n",
        "print('File ID: {}'.format(created.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cjsBYDHuOrbD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#### dataset.zip File ID: 1IstPsPA0mFfgdOMn6XLAMKy0unZFpOFT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z8v0BPhPOrX0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vJgcfY2vQuwC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01JkGG2kQurj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!cp -r /train_summary ./train_summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iPwT_f4GQuju",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_GACvVuQugM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = 'train_summary'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QFFfn6YiRqY5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! curl http://localhost:6006"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgvUH2IERtgv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1\n",
        "! unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ztj8NHK7RtcU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ex6h1o_QRtAR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TN9h5NETRzvR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}